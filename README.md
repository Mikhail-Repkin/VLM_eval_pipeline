# VLM_eval_pipeline

Проект направлен на улучшение автоматизации технической поддержки путем использования Visual Language Models (VLM) для обработки скриншотов, прикрепляемых к обращениям пользователей.

Основные кейсы обработки изображения состоят в:

1) преобразовании визуальной информации из скриншотов в текстовое описание — запрос пользователя, который может быть использован существующими моделями классификации интентов и/или генеративными моделями автоматических ответов на пользовательский запрос.
2) генерации ответа на пользовательские вопросы на основе информации из изображения.

**В этом репозитории представлен пайплайн для тестирования VLM моделей.**

**Целью тестирования является оценка качества работы различных визуально-лингвистических моделей в контексте задач автоматизации технической поддержки.**

Задачами тестирования является:

* Оценка точности генерации текстовых описаний: проверяется, насколько корректно, точно и детализированно модели преобразуют визуальную информацию из скриншотов в текст.
* Сравнение производительности моделей: проводится анализ времени генерации, использования ресурсов и стабильности выходных данных между различными моделями, чтобы определить наиболее оптимальную для production-среды.
* Оценка стабильности и интерпретируемости результатов: анализируется консистентность ответов моделей при одинаковых входных данных, их полезность и релевантность.

Эти задачи помогут определить, какие модели способны лучше справляться с преобразованием визуальной информации в текст, а также выбрать наиболее производительное решение для внедрения в систему технической поддержки.

## Структура директорий

```shell
VLM_eval_pipeline/
├── artifacts/                   # Артефакты результатов тестирования.
│
├── eval/                        # Модули для оценки моделей.
│   ├── autometrics_eval.py      # Методы для оценки автоматических метрик (BLEURT, ROUGE).
│   ├── judge_eval.py            # Классы для оценки с использованием LLM-судьи.
│   ├── reference_eval.py        # Класс для генерации эталонных ответов.
│   ├── tech_metrics_eval.py     # Подсчёт технических характеристик.
│   ├── run_vLLM.py              # Запуск сервера vLLM.
│   └── test_eval.py             # Классы для генерации ответов тест-моделей.
│
├── open_test_dataset/           # Набор тестовых данных (скриншоты) для задачи Screen Annotation.
├── open_test_dataset_VQA/       # Набор тестовых данных (скриншоты и разметка) для задачи VQA.
│
├── test_results_SA/             # Результаты тестирования (Screen Annotation).
│   ├── auto_metrics_stats.xlsx  # Оценки автоматических метрик (BLEURT, ROUGE).
│   ├── judgement_scores.xlsx    # Судейские оценки, полученные от LLM.
│   └── summary_test_stats.xlsx  # Сводные результаты от тест-моделей и тех. статистики.
├── test_results_VQA/            # Результаты тестирования (VQA).
│   ├── auto_metrics_stats.xlsx  # Оценки автоматических метрик (BLEURT, ROUGE).
│   ├── judgement_scores.xlsx    # Судейские оценки, полученные от LLM.
│   └── summary_test_stats.xlsx  # Сводные результаты от тест-моделей и тех. статистики. 
│
├── Test_pipeline_SA.ipynb       # Ноутбук с запуском пайплайна для задачи Screen Annotation.
├── Test_pipeline_VQA.ipynb      # Ноутбук с запуском пайплайна для задачи VQA.
├── README.md                    # Основная документация проекта.
└── requirements.txt             # Список зависимостей для установки.
```

## Список тест-моделей и потребление памяти

**7B МОДЕЛИ:**

|         Model        | Input Length | Quantization | GPU Memory (GB) |
| -------------------- | ------------ | ------------ | --------------- |
| Qwen2-VL-7B-Instruct | 1 — 6144 tok | BF16         | 16.07 — 21.56   |
|                      |              | GPTQ-Int8    | 10.11 — 15.61   |
|                      |              | GPTQ-Int4    | 7.20 — 12.69    |
|                      |              | AWQ          | 7.07 —  12.56   |

**2B МОДЕЛИ:**

| Model                | Input Length | Quantization | GPU Memory (GB) |
| -------------------- | ------------ | ------------ | --------------- |
| Qwen2-VL-2B-Instruct | 1 — 6144 tok | BF16         | 4.68 — 10.01    |
|                      |              | GPTQ-Int8    | 3.55 — 8.87     |
|                      |              | GPTQ-Int4    | 2.91 — 8.21     |
|                      |              | AWQ          | 2.88 — 8.18     |

## Model Inference

Тест-модель разворачивается с помощью фреймворка vLLM раз как сервер, реализующий протокол OpenAI API. По умолчанию сервер запускается по адресу http://localhost:8000.

Сервер использует предопределенный [шаблон чата](https://github.com/vllm-project/vllm/blob/main/docs/source/serving/openai_compatible_server.md#chat-template), хранящийся в токенизаторе.

К этому серверу можно обращаться в том же формате, что и к OpenAI API. Например, чтобы получить список моделей: curl http://localhost:8000/v1/models

## 1. Задача Screen Annotation

### Описание задачи

Задача заключается в автоматическом распознавании, интерпретации и описании различных элементов пользовательского интерфейса (UI) на изображении (скриншоте). Основная цель — оценить способность модели полезно анализировать содержимое скриншота, выделять ключевые элементы и их контекст, а также генерировать человекоподобные описания, которые можно использовать для последующей обработки, например, передачи в модель классификации интента пользователя.

### Сценарий тестирования

* В тестируемую модель подается одна системная промт-инструкция и ссылка на скриншот.
* Сообщение от пользователя в пайплайне тестирования для задачи Screen Annotation не используется.
* Температура тест-моделей: 0.1.
* Всего совершается 5 запусков генерации для 10 скриншотов, что составляет 50 генераций на одну модель.

### Метрики, статистики и оценки

#### Технические статистики

* Общее время генерации (сек.)
* Средняя длина ответа (знаки)
* Скорость генерации — кол-во знаков в секунду
* Количество грамматических ошибок
* Количество некириллических и не англоязычных символов
* Доля англоязычных символов

#### Автоматические метрики

* **Перплексия** — насколько хорошо модель предсказывает последовательности слов (чем ниже, тем лучше).
* **ROUGE-1** — оценка качества машинной генерации текста путём сравнения с эталонным текстом. Сравнение производится по отдельным словам (униграммам).
* **BLEURT** — метрика, основанная на предобученных трансформерах, которая оценивает качество текста по его смысловому сходству с эталонным текстом. BLEURT учитывает синонимы и парафразы, лексическую и семантическую близость, относительную важность различных слов. 0 означает случайный результат, а 1 - идеальный.

#### Субъективная (судейская) оценка

* На основе промпта судья ставит оценки по десятибалльной шкале и подробно объясняет свою оценку.
* Учитывается анонимность ответов. Судья не знает и не учитывает, от какой модели приходит ответ.
* Ответы рандомно меняются местами, чтобы избежать смещения в пользу какой-то одной модели (*position bias* — склонность модели первый ответ оценивать выше).
* В качестве эталонной модели (референс) выступает gpt-4o
* В качестве модели-судьи (LLM-as-a-Judge) выступает gpt-4o-mini
* Оценивается доля соответствия ответов тестируемой модели к ответам эталонной модели, где доля соответствия — отношение судейских оценок: *Candidate Score/Reference Score*.
* Границами оценки является 95%-й доверительный интервал.

### Результаты экспериментов

Ниже приведены результаты сравнения тестируемых моделей с ответами эталона — gpt-4o.

**Результаты технических статистик:**

![tech_stats](artifacts/tech_stats.png)
*Столбцы: название модели, среднее время генерации (сек.), средняя длина текста (знак.), средняя скорость генерации (знак./сек.), Σ орф. ошибок, Σ не ru/en символов (пр. языки), уникальные английские слова в генерации, доля знаков на английском яз.*

* Большинство моделей демонстрируют приемлемое время генерации (от 0.5 до 1.1 секунд), за исключением Qwen2-VL-2B-Instruct-AWQ, которая имеет значительно более высокое время (61.6 секунд) из за фризов генерации.
* У большинства моделей отсутствуют грамматические ошибки, за исключением Qwen2-VL-2B-Instruct-GPTQ-Int4 (5 ошибок) и Qwen2-VL-2B-Instruct (1 ошибка).
* Модели Qwen2-VL-2B-Instruct-GPTQ-Int4 и Qwen2-VL-2B-Instruct-AWQ периодически уходят в генерацию на английском языке, что делает их непрактичным выбором для production.
* Квантованные 7B модели имеют сопоставимую с 2B моделями скорость генерации. Благодаря этому модели Qwen2-VL-7B квантованных версий (Int4, Int8, AWQ) обеспечивают лучшее соотношение скорости и качества.
* Qwen2-VL-7B-Instruct (без квантования) на 25-35% медленнее своих квантованных 7B версий.

**Результаты оценки автоматическими метриками:**

![perplexity](artifacts/perplexity.png)
![rouge](artifacts/rouge.png)
![bleurt](artifacts/bleurt.png)

* В общем случае, модели серии Qwen2-VL-7B имеют более низкую перплексию, и более высокие значения метрик Rouge1 F1 и Bleurt, по сравнению с Qwen2-VL-2B, что указывает на их более высокую способность к генерации текстовых последовательностей и высокую семантическую близость ответов к эталонному описанию.
* Квантованные версии (Int8, Int4, AWQ) моделей, показывают схожие значения метрик в пределах своих серий (2B или 7B).

**Результаты судейской оценки (LLM-as-a-judge):**

![test-to-ref_ratio](artifacts/test-to-ref_ratio.png)

* Модели серии Qwen2-VL-7B показывают более высокую долю соответствия с эталоном, чем Qwen2-VL-2B, что указывает на их лучшие качества генерации текста.
* Наибольшее соответствие с эталоном имеет модель Qwen2-VL-7B-Instruct (0.87) и её квантованные версии: GPTQ-Int8 (0.85), AWQ (0.83), и GPTQ-Int4 с долей 0.79.
* Все модели серии Qwen2-VL-2B имеют значительно меньшую долю соответствия (около 0.5–0.6), что указывает на их ограниченные возможности в задачах генерации.

### Примеры

| Изображение | Эталонный ответ (gpt-4o) |
|-------------|---------------|
| ![test_1](open_test_dataset/test_1.jpg) | Здравствуйте, у меня возникла проблема с покупкой на Ozon. 30.12.2022 в 22:33 попытка покупки на сумму 20 588 ₽ не удалась. Средства были списаны с рублевого счета. Подскажите, пожалуйста, как можно решить эту проблему? |

| Модель | Ответ тест-модели |
|------------|-----------------------|
| Qwen2-VL-7B-Instruct| "Здравствуйте, у меня возникла проблема с покупкой на Ozon. Я пытался сделать заказ на сумму 20 588 рублей, но покупка не удалась. Пожалуйста, помогите разобраться в этой ситуации." |
| Qwen2-VL-7B-Instruct-GPTQ-Int8 | "Здравствуйте, у меня возникла проблема с покупкой на Ozon. Я пытался сделать покупку за 20 588 рублей, но заказ не был успешно завершен. Пожалуйста, помогите разобраться в этой ситуации." |
| Qwen2-VL-7B-Instruct-GPTQ-Int4 | "Привет, мне не удалось совершить покупку на сумму 20 588 рублей. Пожалуйста, помогите разобраться в этой ситуации." |
| Qwen2-VL-7B-Instruct-AWQ | "Привет, мне не удалось совершить покупку на Ozon. У меня было 20 588 рублей на счету. Помоги мне разобраться в этой ситуации, пожалуйста." |
| Qwen2-VL-2B-Instruct | "Привет, у меня есть проблема с покупкой на Ozon. Стоимость покупки составляет 20 588 рублей. Я не могу удалить покупку, и мне нужно помощь. Спасибо!" |
| Qwen2-VL-2B-Instruct-GPTQ-Int8 | "Как я могу помочь вам с вашим заказом на Ozon?" |
| Qwen2-VL-2B-Instruct-GPTQ-Int4 | "Hello, I have a question about my Ozon account. I accidentally made a purchase that I didn't want to. Can you help me delete it? I need to refund the money. Thank you for your assistance." |
| Qwen2-VL-2B-Instruct-AWQ | "Hello, I have a question about my account. I have received a message from the bank saying that my account has been frozen. Can you please help me understand what happened and how I can recover my account? Thank you." |

| Изображение | Эталонный ответ (gpt-4o) |
|-------------|---------------|
| ![test_2](open_test_dataset/test_2.jpg) | Здравствуйте! У меня возникла проблема с оплатой заказа. В приложении указано, что заказ не оплачен, и предлагается повторить оплату или изменить способ оплаты. Однако я не могу завершить процесс. Можете помочь решить эту проблему? Спасибо! |

| Модель | Ответ тест-модели |
|------------|-----------------------|
| Qwen2-VL-7B-Instruct| "Здравствуйте, у меня возникла проблема с оплатой заказа. Когда я пытался оплатить, система сообщила об ошибке. Пожалуйста, помогите мне решить эту проблему. Спасибо!" |
| Qwen2-VL-7B-Instruct-GPTQ-Int8 | Здравствуйте, у меня возникла проблема с оплатой заказа. Когда я нажимаю на кнопку "Оплатить", ничего не происходит. Пожалуйста, помогите мне разобраться в этой ситуации. |
| Qwen2-VL-7B-Instruct-GPTQ-Int4 | "Здравствуйте, у меня возникла проблема с оплатой заказа. Я нажал на кнопку "Оплатить" и выбрал способ оплаты "Ozon Карта", но система сообщила об ошибке оплаты. Пожалуйста, помогите мне разрешить эту проблему. Спасибо!" |
| Qwen2-VL-7B-Instruct-AWQ | Привет, мне нужна помощь с моим заказом. Я не смогла оплатить его через Ozon Карта. Пожалуйста, помогите мне повторно оплатить или изменить способ оплаты. |
| Qwen2-VL-2B-Instruct | "Здравствуйте, у меня возникла проблема с оплатой заказа. Я не могу оплатить его, и мне нужно повторить оплату или изменить способ оплаты. Пожалуйста, помогите мне с этим." |
| Qwen2-VL-2B-Instruct-GPTQ-Int8 | "Заказ не оплачен. Ошибка оплаты. Попробуйте повторить оплату или изменить способ оплаты. Перейти к оплате" |
| Qwen2-VL-2B-Instruct-GPTQ-Int4 | "Я не могу оплатить свой заказ, который был заблокирован. Пожалуйста, повторите попытку оплаты или измените способ оплаты." |
| Qwen2-VL-2B-Instruct-AWQ | "Здравствуйте, у меня есть проблема с оплатой. Я не могу оплатить 43 рубля. Пожалуйста, повторите оплату или измените способ оплаты. Я отправил 43 рубля на карту Озон. Пожалуйста, перейти к оплате." |

| Изображение | Эталонный ответ (gpt-4o) |
|-------------|---------------|
| ![test_10](open_test_dataset/test_10.jpg) | Здравствуйте. Мой заказ с номером 02632305-0222 был отменен 23 октября в 20:32. Причина отмены указана как «Не применилась скидка или промокод». Можете объяснить, почему это произошло, и как можно решить эту проблему? |

| Модель | Ответ тест-модели |
|------------|-----------------------|
| Qwen2-VL-7B-Instruct| Здравствуйте, я недавно сделал заказ на товары в интернет-магазине, но заказ был отменен. Причина отмены - не была применена скидка или промокод. Могли бы вы, пожалуйста, проверить, почему это произошло и как я могу исправить ситуацию? |
| Qwen2-VL-7B-Instruct-GPTQ-Int8 | Здравствуйте, я недавно сделал заказ на товары в интернет-магазине, но заказ был отменен. Причина отмены - не была применена скидка или промокод. Могли бы вы, пожалуйста, помочь мне с этим? |
| Qwen2-VL-7B-Instruct-GPTQ-Int4 | Здравствуйте, у меня есть вопрос по заказу от 23 октября, номер 02632305-0222. Доставка была отменена в 20:32, причина - не была применена скидка или промокод. Могли бы вы, пожалуйста, объяснить, как я могу исправить эту ситуацию? |
| Qwen2-VL-7B-Instruct-AWQ | Здравствуйте, я недавно сделал заказ на товары в интернет-магазине. Мой заказ был отменен 23 октября в 20:32 по причине того, что не была применена скидка или промокод. Могли бы вы проверить, почему это произошло и как я могу исправить ситуацию? |
| Qwen2-VL-2B-Instruct | "Здравствуйте, у меня есть проблема с заказом, который я оформил 23 октября. Я не могу получить его в пункте выдачи, и мне нужно отменить этот заказ. Дата отмены: 23 октября в 20:32. Причина отмены: Скидка или промокод не использовалась. Спасибо за вашу помощь!" |
| Qwen2-VL-2B-Instruct-GPTQ-Int8 | "Здравствуйте, у меня есть проблема с заказом, который я оформил 23 октября. Я не могу получить его в пункте выдачи, и мне нужно отменить этот заказ. Дата отмены: 23 октября в 20:32. Причина отмены: Скидка или промокод не была использована. Спасибо за вашу помощь!" |
| Qwen2-VL-2B-Instruct-GPTQ-Int4 | "Здравствуйте, у меня был заказ от 23-го октября, номер телефона 02632305-0222. Я хотел бы отменить доставку в пункт выдачи. Дата отмены: 23-го октября в 20:32. Причина отмены: не применялась скидка или промокод." |
| Qwen2-VL-2B-Instruct-AWQ | "Здравствуйте, у меня есть проблема. Я заказал товар 23 октября, но мне отказали в доставке. Дата отказа: 23 октября в 20:32. Причина отказа: не использовал скидку или промокод. Спасибо за вашу помощь." |

## 2. Задача Visual Question Answering

Задача заключается в разработке системы, способной отвечать на пользовательские вопросы на основе анализа изображения. Основная цель — оценить способность модели извлекать визуальную информацию, интерпретировать её и интегрировать с текстовым контекстом, чтобы дать осмысленные и точные ответы.

### Сценарий тестирования

* В тестируемую модель подается системная промт-инструкция, вопрос пользователя и ссылка на скриншот.
* Температура тест-моделей: 0.1.
* Разметка 79 скриншотов содержит по два вопрос-ответа. Совершается один запуск генерации на вопрос, т.е. 158 генераций на одну модель.

### Метрики, статистики и оценки

#### Технические статистики и Автоматические метрики

[Аналогично задаче Screen Annotation](https://github.com/Mikhail-Repkin/VLM_eval_pipeline?tab=readme-ov-file#технические-статистики)

#### Субъективная (судейская) оценка

* Судья сравнивает ответ от тест модели с эталонным человеческим ответом, ставит оценку по десятибалльной шкале и подробно объясняет свою оценку.
* Анонимность и перемешивание ответов не требуется.
* В качестве эталонных ответов выступает человеческая разметка датасета.
* В качестве модели-судьи (LLM-as-a-Judge) выступает Deepseek-3.
* Оценивается доля соответствия ответов тестируемой модели к эталонным человеческим ответам (имеющим Score 10), где доля соответствия — отношение судейских оценок: *Candidate Score/10*.
* Границами оценки является 95%-й доверительный интервал.

### Результаты экспериментов

**Результаты технических статистик:**
![tech_stats_VQA](artifacts/tech_stats_VQA.png)
*Столбцы: название модели, среднее время генерации (сек.), средняя длина текста (знак.), средняя скорость генерации (знак./сек.), Σ орф. ошибок, Σ не ru/en символов (пр. языки), уникальные английские слова в генерации, доля знаков на английском яз.*

* Увеличение объема входных данных в задаче VQA (более длинный системный промт, пользовательский запрос и картинка с большим разрешением) привело к снижению скорости генерации ответа моделями примерно в 2 раза, по сравнению с задачей Screen Annotation.
* Тем не менее, 7B модели имеют приемлимое среднее время выполнения ~1.0 сек.
* Модели с 2B параметров показывают тенденцию к генерации более длинных ответов и снижение средней скорости генерации.
* Также модели Qwen2-VL-2B демонстрируют высокую частоту ошибок, отказов и генерации на английском языке, что делает их не стабильными для использования.

**Результаты оценки автоматическими метриками:**

![perplexity_VQA](artifacts/perplexity_VQA.png)
![rouge_VQA](artifacts/rouge_VQA.png)
![bleurt_VQA](artifacts/bleurt_VQA.png)

* Как и в результатах тестирования на задаче Screen Annotation, модели 7B-серии имеют более высокую способность к генерации текстовых последовательностей и высокую семантическую близость ответов к эталону, чем Qwen2-VL-2B.

**Результаты судейской оценки (LLM-as-a-judge):**

![test-to-ref_ratio_VQA](artifacts/test-to-ref_ratio_VQA.png)

* В связи с тем, что часть вопросов в датасете для задачи Visual Question Answering не содержат прямого ответа в сопутствующем изображении, модели имеют более высокую склонность галлюцинировать и оценки моделей в данной задаче получаются более низкими, чем в задаче Screen Annotation.
* Однако, тенденция относительного качества двух семейств моделей, 7B и 2B, остается схожей.
* Модели серии Qwen2-VL-7B показывают более высокую долю соответствия с эталоном, чем Qwen2-VL-2B, что указывает на их лучшие качества генерации текста.
* Наибольшее соответствие с эталоном имеет модель Qwen2-VL-7B-Instruct (0.69) и её квантованные версии: GPTQ-Int8 (0.68), GPTQ-Int4 (0.67), и AWQ с долей (0.66).
* Все модели серии Qwen2-VL-2B имеют меньшую долю соответствия (около 0.4–0.5), что указывает на их ограниченные возможности в задачах VQA.

### Примеры

| Изображение | Вопрос | Эталонный ответ |
|-------------|--------| ----------------|
| ![17-46-31](open_test_dataset_VQA/phone/17-46-31.jpg) | Что делать, если сумма перевода превышает лимиты счета? | Нажмите на кнопку "Повысить лимиты", чтобы изменить текущие лимиты и иметь возможность перевести большую сумму. |

| Модель | Ответ тест-модели |
|------------|-----------------------|
| Qwen2-VL-7B-Instruct| Если сумма перевода превышает лимиты счета, вам нужно увеличить лимиты счета. Для этого нажмите на кнопку "Повысить лимиты". |
| Qwen2-VL-7B-Instruct-GPTQ-Int8 | Если сумма перевода превышает лимиты счета, вам нужно увеличить лимиты счета. Для этого нажмите на кнопку "Повысить лимиты". |
| Qwen2-VL-7B-Instruct-GPTQ-Int4 | 1. Нажмите на кнопку "Повысить лимиты" для увеличения лимитов счета. 2. Следуйте инструкциям, чтобы повысить лимиты. |
| Qwen2-VL-7B-Instruct-AWQ | Если сумма перевода превышает лимиты счета, вам нужно нажать на кнопку "Повысить лимиты". |
| Qwen2-VL-2B-Instruct | Чтобы повысить лимиты счета, пользователь должен: 1. Нажать на кнопку "Повысить лимиты" на экране. 2. Ввести новые лимиты, которые он считает приемлемыми для своих операций. 3. Нажать на кнопку "Подтвердить" или "Применить" для подтверждения изменения лимитов. |
| Qwen2-VL-2B-Instruct-GPTQ-Int8 | Возможно, нужно увеличить лимиты счета, чтобы перевести больше. |
| Qwen2-VL-2B-Instruct-GPTQ-Int4 | Возможно, вам нужно увеличить лимиты своего счета. |
| Qwen2-VL-2B-Instruct-AWQ | Возможны следующие действия: 1. Повысить лимиты счета: Повысить лимиты счета, чтобы переводить больше. 2. Вернуться: Вернуться к предыдущему экрану. |

| Изображение | Вопрос | Эталонный ответ |
|-------------|--------| ----------------|
| ![test_2_VQA](open_test_dataset_VQA/phone/17-46-34.jpg) | Как пополнить счет на 500 рублей? | Выберите банк для пополнения, нажав на иконку с соответствующим логотипом, и следуйте инструкциям. |

| Модель | Ответ тест-модели |
|------------|-----------------------|
| Qwen2-VL-7B-Instruct| 1. Нажмите на кнопку "Сбербанк" или "Другой банк" для выбора банка для пополнения счета 2. Введите сумму 500 рублей. 3. Подтвердите операцию. |
| Qwen2-VL-7B-Instruct-GPTQ-Int8 | 1. Нажмите на кнопку "Пополнить другим способом". 2. Выберите банк для пополнения. 3. Введите сумму 500 рублей. 4. Подтвердите операцию. |
| Qwen2-VL-7B-Instruct-GPTQ-Int4 | 1. Нажмите на кнопку "Пополнить другим способом" внизу экрана. 2. Выберите "Сбербанк" или "Другой банк" в зависимости от вашего банка. 3. Следуйте инструкциям на экране для ввода информации о банковской карте или другого способа пополнения счета. |
| Qwen2-VL-7B-Instruct-AWQ | 1. Нажмите на кнопку "Выберите банк для пополнения". 2. Выберите "Сбербанк". 3. Следуйте инструкциям на экране для завершения перевода. |
| Qwen2-VL-2B-Instruct | Чтобы пополнить счет на 500 рублей, вы можете выбрать любой из следующих банков: 1. Сбербанк 2. Другой банк |
| Qwen2-VL-2B-Instruct-GPTQ-Int8 | Чтобы пополнить счет на 500 рублей, вы можете выбрать Сбербанк или другой банк. |
| Qwen2-VL-2B-Instruct-GPTQ-Int4 | Чтобы пополнить счет на 500 рублей, вы должны выбрать другой банк для пополнения. |
| Qwen2-VL-2B-Instruct-AWQ | Чтобы пополнить счет на 500 рублей, вы можете выбрать Сбербанк или другой банк для пополнения. |

| Изображение | Вопрос | Эталонный ответ |
|-------------|--------| ----------------|
| ![test_3_VQA](open_test_dataset_VQA/phone/17-46-43.jpg) | Что делать с этой ошибкой? | Следуйте рекомендации в приложении и попробуйте зайти позже, так как техническая команда работает над исправлением. |

| Модель | Ответ тест-модели |
|------------|-----------------------|
| Qwen2-VL-7B-Instruct| На экране отображается сообщение "Что-то пошло не так. Работаем над исправлением. Пожалуйста, зайдите позже". Это означает, что приложение временно недоступно. Пользователю следует попробовать зайти в приложение позже. |
| Qwen2-VL-7B-Instruct-GPTQ-Int8 | Извините, но на данный момент в приложении Ozon Банка нет доступа к вашим финансовым данным. Пожалуйста, попробуйте зайти позже. |
| Qwen2-VL-7B-Instruct-GPTQ-Int4 | Извините, но на данный момент интерфейс приложения показывает сообщение "Что-то пошло не так. Работаем над исправлением. Пожалуйста, зайдите позже". Это означает, что приложение временно недоступно. Пожалуйста, попробуйте снова позже. |
| Qwen2-VL-7B-Instruct-AWQ | На экране отображается сообщение "Что-то пошло не так. Работаем над исправлением. Пожалуйста, зайдите позже". Это означает, что текущий сервис временно недоступен. Пожалуйста, попробуйте снова позже или свяжитесь с поддержкой для получения дополнительной помощи. |
| Qwen2-VL-2B-Instruct | Извините, но я не могу помочь с решением этой ошибки. |
| Qwen2-VL-2B-Instruct-GPTQ-Int8 | Извините, но я не могу предоставить вам конкретную информацию о том, что происходит с вашим аккаунтом в мобильном приложении Ozon Банка. Могу ли я помочь вам с чем-то другим? |
| Qwen2-VL-2B-Instruct-GPTQ-Int4 | К сожалению, вы не предоставили конкретную ошибку, которую вы хотите решить. Пожалуйста, укажите, что именно вы имеете в виду, и я помогу вам с этим. |
| Qwen2-VL-2B-Instruct-AWQ | Sorry, but I can't assist with that. |

## 3. Рекомендации

* Квантованные Qwen2-VL-7B модели имеют хорошую скорость генерации, показывают более качественные и стабильные результаты.
* Для задач, требующих максимального качества генерации следует выбирать Qwen2-VL-7B, включая квантованные версии (Int8, Int4, AWQ).
* Модели семейства Qwen2-VL-7B могут использоваться для:
  * описания различных элементов пользовательского интерфейса на изображении и генерации человекоподобного описания/вопроса с целью передачи в модель классификации интента пользователя,
  * генерации осмысленных и точных ответов при условии содержания ответа на изображении. Если скриншот не содержит прямого ответа на пользовательский вопрос, можно использовать RAG для повышения релевантности и точности ответа.
* Квантование малых Qwen2-VL-2B моделей ведет к проблемам генерации (отказы генерации, грамматические ошибки, смена языка), малую семантическую близость к эталону, и не рекомедуются к использованию в продакшен-среде.